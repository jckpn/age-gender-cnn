{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook is useful as we can keep datasets in memory between training runs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing 6667 files from C:\\Users\\jckpn\\Documents\\YEAR 3 PROJECT\\implementation\\source\\utkface_itw...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6667 items successfully prepared\n",
      "\n",
      "Split dataset into 6400 training and 1599 validation examples\n"
     ]
    }
   ],
   "source": [
    "# Don't cache other files https://stackoverflow.com/a/57245926\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train import train_model\n",
    "from torch.utils.data import random_split, ConcatDataset\n",
    "from face_dataset import *\n",
    "from label_funcs import *\n",
    "import preprocessor\n",
    "from ds_transforms import *\n",
    "\n",
    "# Define dataset parameters\n",
    "ds_size = 6667\n",
    "equalise = False\n",
    "processor = preprocessor.processor(w=28, h=28)\n",
    "transform = alexnet_transform(size=28)\n",
    "equalise = False\n",
    "augment = False\n",
    "print_errors = False\n",
    "\n",
    "# adience_gender_ds = FastDataset(\n",
    "#     'C:\\\\Users\\\\jckpn\\\\Documents\\\\YEAR 3 PROJECT\\\\implementation\\\\source\\\\datasets\\\\training\\\\adience',\n",
    "#     label_func=age_label_all, transform=transform, processor=processor,\n",
    "#     ds_size=ds_size, print_errors=print_errors, equalise=equalise,\n",
    "#     augment=augment)\n",
    "\n",
    "imdb_gender_ds = FastDataset(\n",
    "    'C:\\\\Users\\\\jckpn\\\\Documents\\\\YEAR 3 PROJECT\\\\implementation\\\\source\\\\other\\\\imdb_crop',\n",
    "    label_func=age_label_all, transform=transform, processor=processor,\n",
    "    ds_size=ds_size, print_errors=print_errors, equalise=equalise,\n",
    "    augment=augment)\n",
    "\n",
    "wiki_gender_ds = FastDataset(\n",
    "    'C:\\\\Users\\\\jckpn\\\\Documents\\\\YEAR 3 PROJECT\\\\implementation\\\\source\\\\datasets\\\\training\\\\raw_imdbwiki_crop\\\\wiki_crop',\n",
    "    label_func=age_label_all, transform=transform, processor=processor,\n",
    "    ds_size=ds_size, print_errors=print_errors, equalise=equalise,\n",
    "    augment=augment)\n",
    "\n",
    "utkface_gender_ds = FastDataset(\n",
    "    'C:\\\\Users\\\\jckpn\\\\Documents\\\\YEAR 3 PROJECT\\\\implementation\\\\source\\\\utkface_itw',\n",
    "    label_func=age_label_all_utk, transform=transform, processor=processor,\n",
    "    ds_size=ds_size, print_errors=print_errors, equalise=equalise,\n",
    "    augment=augment)\n",
    "    \n",
    "train_val_set = ConcatDataset([wiki_gender_ds, imdb_gender_ds, utkface_gender_ds])\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "val_split_ratio = 0.2\n",
    "val_size = int(val_split_ratio * len(train_val_set))\n",
    "train_size = len(train_val_set) - val_size\n",
    "train_set, val_set = random_split(train_val_set, [train_size, val_size])\n",
    "print(f'Split dataset into {len(train_set)} training and {len(val_set)} validation examples')\n",
    "\n",
    "test_set = val_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train desired models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING MODEL LeNet-1_2604-1524.pt WITH PARAMS:\n",
      " - Architecture: LeNet\n",
      " - Learning rate: 0.0001\n",
      " - Optimizer: Adam\n",
      " - Loss function: MSELoss()\n",
      " - Other notes: None\n",
      "\n",
      "+---------------+---------------+---------------+---------------+---------------+\n",
      "|         EPOCH | EXAMPLES SEEN |    TRAIN LOSS |      VAL LOSS |  ELAPSED TIME |\n",
      "+---------------+---------------+---------------+---------------+---------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|             1 |          6400 |       0.03861 |       0.03138 |          0:17 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|             2 |         12800 |       0.02916 |       0.02934 |          0:34 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|             3 |         19200 |       0.02644 |       0.02499 |          0:51 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|             4 |         25600 |       0.02442 |       0.02412 |          1:11 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| *           5 |         32000 |       0.02383 |       0.02451 |          1:28 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|             6 |         38400 |       0.02313 |       0.02375 |          1:46 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| *           7 |         44800 |       0.02249 |       0.02441 |          2:06 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|             8 |         51200 |       0.02238 |       0.02352 |          2:23 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|             9 |         57600 |       0.02209 |       0.02341 |          2:40 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| *          10 |         64000 |       0.02195 |       0.02388 |          2:58 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            11 |         70400 |       0.02177 |       0.02336 |          3:15 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            12 |         76800 |       0.02156 |       0.02325 |          3:31 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            13 |         83200 |       0.02148 |       0.02303 |          3:47 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| *          14 |         89600 |       0.02134 |       0.02304 |          4:03 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| **         15 |         96000 |       0.02129 |       0.02328 |          4:21 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ***        16 |        102400 |       0.02126 |       0.02303 |          4:37 |\n",
      "+---------------+---------------+---------------+---------------+---------------+\n",
      "\n",
      "Halting training - 3 epochs without improvement\n",
      "\n",
      "Training took 4m 37s (17.0s per epoch)\n",
      "\n",
      "Best model from session saved to '../models\\LeNet-1_2604-1524.pt'\n",
      "\n",
      "Testing model accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11500172143991927"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from torch.nn import CrossEntropyLoss, Loss  # classif. -> CEL, regress. -> MSE\n",
    "from torch.optim import Adam, SGD\n",
    "from networks import *\n",
    "import tests\n",
    "\n",
    "model = train_model(\n",
    "    model=LeNet(1), \n",
    "    train_set=train_set,\n",
    "    val_set=val_set,\n",
    "    loss_fn=MSELoss(),\n",
    "    optim_fn=Adam,\n",
    "    learning_rate=0.0001,\n",
    "    patience=3,\n",
    "    model_save_dir='../models')\n",
    "\n",
    "tests.mae(model, test_set, print_results=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
